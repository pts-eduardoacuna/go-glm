{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ultimate Data\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Based on Gophercon 2017 [Daniel Whitenack's Ultimate Data - Introduction](https://github.com/ardanlabs/gotraining/blob/master/topics/courses/data/introduction/README.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Introduction to Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### What is Data Analysis?\n",
    "\n",
    "Data analysis transforms datasets into **insights** that have corresponding **actions** and **consequences**.\n",
    "\n",
    "#### Prepare your mind\n",
    "\n",
    "Before and during any data analytics project, you must be able to answer the following questions:\n",
    "\n",
    "- What insights do I want to generate?\n",
    "- What actions are triggered by the insights?\n",
    "- What are the consequences of those actions?\n",
    "- What do the results need to contain to best represent the desired insights?\n",
    "- What is the data required to produce a valid result?\n",
    "- How will I measure the validity of results?\n",
    "- Can the results be effectively conveyed to decision makers as insights?\n",
    "- Am I confident in the results?\n",
    "\n",
    "#### Order of Operations\n",
    "\n",
    "Data analytics projects should follow these steps in this order:\n",
    "\n",
    "1. Understand the insights, actions and consequences involved.\n",
    "2. Understand the relevant data to be gathered and analyzed.\n",
    "3. Gather and organize the relevant data.\n",
    "4. Understand the expectations for determining valid results.\n",
    "5. Determine the most interpretable process that can produce valid results.\n",
    "6. Determine how you will test the validity of results.\n",
    "7. Develop the determined process and tests.\n",
    "8. Test the results and evaluate against your expectations.\n",
    "9. Refactor as necessary.\n",
    "10. Looks for ways to simplify, minimize and reduce.\n",
    "\n",
    "#### Guidelines, Decision Making and Trade-Offs\n",
    "\n",
    "Develop your design philosophy around these major categories in this order: Integrity, Value, Readability/Interpretability, and Performance.\n",
    "\n",
    "**1) Integrity** - Generating bad insights may cause irreparable damage to real people.\n",
    "- Error handling code in the main code.\n",
    "- You must understand the data.\n",
    "- Control the input and output of your processes.\n",
    "- You must be able to reproduce results.\n",
    "\n",
    "**2) Value** - ust because you can produce a result, does not mean the result contains value.\n",
    "- If an action can not be taken based on a result, the result does not have value.\n",
    "- If the impact of a result can not be measured, the result does not have value.\n",
    "\n",
    "**3) Readability and Interpretability** - Avoid unnecessary data transformations and analysis complexity that hides:\n",
    "- The cost/impact of individual steps of the analyses.\n",
    "- The underlying purpose of the data transformations and analyses.\n",
    "\n",
    "**4) Performance** - Make your analyses run as fast as possible and produce results that minimize a given measure of error. When code is written with this as the priority, it is very difficult to write code that is readable, simple or idiomatic.\n",
    "\n",
    "![](https://github.com/ardanlabs/gotraining/raw/master/topics/data/data_analysis/forbes_data_science.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pachyderm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pachyderm lets you deploy and manage multi-stage, language-agnostic data pipelines while maintaining complete reproducibility and provenance.\n",
    "\n",
    "#### Version control for data\n",
    "\n",
    "Pachyderm version controls data, similar to what Git does with code. You can track the state of your data over time, backtest models on historical data, share data with teammates, and revert to previous states of data.\n",
    "\n",
    "![](http://www.pachyderm.io/images/pachyderm-graph.png)\n",
    "\n",
    "#### Language-agnostic data pipelines\n",
    "\n",
    "Pachyderm lets you use the tools and frameworks you need, from bash scripts to Tensorflow. You just declaratively tell Pachyderm what you want to run, and Pachyderm takes care of triggering, data sharding, parallelism, and resource management on the backend.\n",
    "\n",
    "![](http://www.pachyderm.io/images/pachyderm-factory.png)\n",
    "\n",
    "For more information visit the [local installation](http://pachyderm.readthedocs.io/en/latest/getting_started/local_installation.html) site and the [beginner tutorial](http://pachyderm.readthedocs.io/en/latest/getting_started/beginner_tutorial.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Go",
   "language": "go",
   "name": "gophernotes"
  },
  "language_info": {
   "name": "go"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
